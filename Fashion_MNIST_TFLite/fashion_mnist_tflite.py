# -*- coding: utf-8 -*-
"""Fashion_MNIST_TFLite.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D5k7hfAqbBemVXgJF7HpCRP_LNFtRMCJ
"""
# TensorFlow
import tensorflow as tf
import tensorflow_datasets as tfds
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import pathlib
import time
from os import getcwd

splits = tfds.Split.ALL.subsplit(weighted=(80, 10, 10))

filePath = f"{getcwd()}/../tmp2/"
splits, info = tfds.load('fashion_mnist', with_info=True, as_supervised=True, split=splits, data_dir=filePath)

(train_examples, validation_examples, test_examples) = splits

num_examples = info.splits['train'].num_examples
num_classes = info.features['label'].num_classes

class_names = ['T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# Create a labels.txt file with the class names
with open('labels.txt', 'w') as f:
    f.write('\n'.join(class_names))

# The images in the dataset are 28 by 28 pixels.
IMG_SIZE = 28

""" **Preprocess the data**"""
def format_example(image, label):
    # Cast image to float32
    image = tf.cast(image, dtype=tf.float32)
    
    # Normalize the image in the range [0, 1]
    image = image / 255.0
    
    return image, label

# Specify the batch size
BATCH_SIZE = 16

# Create Datasets
train_batches = train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)
validation_batches = validation_examples.cache().batch(BATCH_SIZE).map(format_example)
test_batches = test_examples.map(format_example).batch(1)

"""##**Test the model with TFLite Interpreter**"""

# Load TFLite model and allocate tensors.
tflite_model = "fashion_mnist_model.tflite"
interpreter = tf.lite.Interpreter(model_path=tflite_model)
interpreter.allocate_tensors()

input_index = interpreter.get_input_details()[0]["index"]
output_index = interpreter.get_output_details()[0]["index"]

# Gather results for the randomly sampled test images
predictions = []
test_labels = []
test_images = []
inference_timings = []
predicted_labels = []
actual_labels = []

for img, label in test_batches.take(50):
    cur = time.time()

    interpreter.set_tensor(input_index, img)
    interpreter.invoke()
    
    result = interpreter.get_tensor(output_index)
    
    predictions.append(result)
    test_labels.append(label[0])
    test_images.append(np.array(img))
    predicted_labels.append(int(np.argmax(result)))
    actual_labels.append(label[0])
    
    end = time.time()
    inference_timings.append(end-cur)

# Utilities functions for plotting

def plot_image(i, predictions_array, true_label, img):
    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    
    img = np.squeeze(img)
    
    plt.imshow(img, cmap=plt.cm.binary)
    
    predicted_label = np.argmax(predictions_array)
    
    if predicted_label == true_label.numpy():
        color = 'green'
    else:
        color = 'red'
        
    plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                         100*np.max(predictions_array),
                                         class_names[true_label]),
                                         color=color)

def plot_value_array(i, predictions_array, true_label):
    predictions_array, true_label = predictions_array[i], true_label[i]
    plt.grid(False)
    plt.xticks(list(range(10)))
    plt.yticks([])
    thisplot = plt.bar(range(10), predictions_array[0], color="#777777")
    plt.ylim([0, 1])
    predicted_label = np.argmax(predictions_array[0])
    
    thisplot[predicted_label].set_color('red')
    thisplot[true_label].set_color('blue')


#Pick any random image index from  1-50 for testing
index = 25 

plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(index, predictions, test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(index, predictions, test_labels)

for i in range(50):
    print("Predicted labels: "+str(predicted_labels[i])+" Actual labels: "+str(actual_labels[i])+" Inference time(s): "+str(inference_timings[i]))

#plt.show() doesn't work on Raspberry Pi, use plt.savefig() instead
plt.savefig('result.svg')
